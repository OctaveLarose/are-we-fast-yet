---
title: "Section 5.6 Impact of Optimizations"
output: html_document
---

```{r load-scripts, echo=FALSE, include=FALSE}
# load libraries, the data, and prepare it
source("scripts/libraries.R", chdir=TRUE)
source("scripts/data-processing2.R")

OPTIM_GRAPH_HEIGHT <- 1.3
OPTIM_GRAPH_WIDTH <- 2.6

compute_stats <- function(data, exe_name, iteration_threshold = 0, baseline_optim="all optimizations") {
  # compute_stats(data_optim_pysom_ast, "RPySOM-ast-interp")
  # data <- data_optim_pysom_ast
  # exe_name <- "RPySOM-ast-interp"
  
  # remove all the columns we don't need for this
  # and keep only the exe we are interested in
  data <- data |>
    select(!c(commitid, suite, cmdline, varvalue, cores, trialid, inputsize, extraargs, warmup, invocation)) |>
    filter(exe == exe_name)
  
  # then selected the "warmed up data"
  jit_exe_vals <- c("RPySOM-bc-jit", "RPySOM-ast-jit", "TruffleSOM-graal", "TruffleSOM-graal-bc")
  if (exe_name %in% jit_exe_vals) {
    data <- data %>% filter(iteration >= MIN_JIT_ITERATION)
  } else {
    data <- data %>% 
      filter(iteration >= iteration_threshold)    
  }
  
  # now, and only now, let's isolate the baseline, and pick the median
  base <- data |>
    filter(optim == baseline_optim) |>
    select(!c(optim)) |>
    group_by(bench) |>
    summarise(base_value = median(value))
  
  # and finally, we can normalize things
  norm <- data |>
    left_join(base, by = c("bench")) |>   # add the base_value column per join
    transform(ratio = value / base_value) # do the unit conversion
  
  # TODO: remove, this is needed because we have old benchmarks in there
  norm <- norm |>
    filter(!is.na(base_value))

  # summarize normalized results per benchmark
  # we only want one value per benchmark, and the median seems a good choice
  # mean might not be valid because of our unit conversion (it should, but who knows statistics...)
  # anyway, do get statistics for an experiment, we really want only one value per benchmark
  
  per_bench <- norm |>
    group_by(optim, exe, bench) |>
    summarize(
      unit = unit[1],
      median_ratio = median(ratio),
      .groups = "drop")
  
  # now get the overall stats
  # the min, max, and median, each corresponding to exactly one benchmark
  # and the specific values happen to be the median we measured for that benchmark
  stats <- per_bench |>
    group_by(optim, exe) |>
    summarise(
      unit = unit[1],
      min = min(median_ratio),
      max = max(median_ratio),
      median = median(median_ratio),
      .groups = "drop")

  list(
    base = base,
    norm = per_bench,
    stats = stats)
}

get_data_for_box_plot_optim <- function(input_data, exe_name, baseline_optim_name="all optimizations", iteration_threshold=0) {
  all <- compute_stats(input_data, exe_name, iteration_threshold)
  all$norm # %>% filter(!is.na(expid.y))
}

box_plot_optim <- function(data, custom_x_breaks=NULL, colors = color_set_optims) {
  if (is.null(custom_x_breaks))
    x_breaks <- c(0.5, 0.8, 1, 1.5, 2, 3, 5, 10, 15, 30, 50, 100, 300)
  else
    x_breaks <- custom_x_breaks

  plot <- ggplot(data, aes(x=median_ratio, y=reorder(factor(optim), -median_ratio, FUN = median)))
  plot <- plot + 
    geom_vline(aes(xintercept=1),    colour="#999999", linetype="solid") +
    geom_vline(aes(xintercept=1.5),  colour="#999999", linetype="dotted") +
    geom_vline(aes(xintercept=2), colour="#999999", linetype="dotted") #+
#    geom_vline(aes(xintercept=10), colour="#999999", linetype="dotted")
  plot <- plot + geom_boxplot(outlier.size = 0.7,
                              outlier.alpha = 0.6,
                              width=0.5,
                              outlier.shape = 22,
                              aes(colour = optim, fill = optim), 
                              alpha=0.5) +
    scale_x_log10(breaks = x_breaks) +
    scale_color_manual(values = colors) +
    scale_fill_manual(values = colors) +
    theme_simple() +
    theme(
      axis.text.x = element_text(angle= 90, vjust=0.5, hjust=1),
      axis.title.x  = theme_simple_axis_title(),
      legend.position="none") +
    #scale_y_log10(breaks=c(1,2,3,10,20,30,50,100,200,300,500,1000)) + #limit=c(0,30), breaks=seq(0,100,5), expand = c(0,0)
    ylab("") +
    xlab("normalized run time, lower is better")
  
  plot
}

box_plot_optim_unified <- function(data, custom_x_breaks=NULL) {
  if (is.null(custom_x_breaks))
    x_breaks <- c(0.5, 0.8, 1, 1.5, 2, 3, 5, 10, 15, 30, 50, 100, 300)
  else
    x_breaks <- custom_x_breaks
  
#  breaks <- levels(droplevels(data)$optim)
  #vm_colors <- rainbow(255)
  col_values <- rainbow(10)
  
  plot <- ggplot(data, aes(x=median_ratio, y=optim, fill = optim))
  plot <- plot + geom_boxplot(outlier.size = 0.5) +
    scale_x_log10(breaks = x_breaks) +
    scale_fill_viridis_d() +
    theme_simple() +
    theme(
      axis.text.x = element_text(angle= 90, vjust=0.5, hjust=1),
      axis.title.x = theme_simple_axis_title(),
      legend.position="none") +
    #scale_y_log10(breaks=c(1,2,3,10,20,30,50,100,200,300,500,1000)) + #limit=c(0,30), breaks=seq(0,100,5), expand = c(0,0)
    ylab("") +
    xlab("") + 
    geom_hline(yintercept = 8.5, linetype = "dotted")
  
  plot
}

# was acquired through the new Dockerfile unified config. as opposed to the previous "we run everything individually on its own branch" approach
# so the results are formatted differently and we need to do some plumbing
get_and_format_new_data <- function(data) {
  data$optim <- sub("^.*-no-(.*)$", "no-\\1", data$exe)
  data$exe <- sub("^(.*)-no-.*$", "\\1", data$exe)
  
  # renaming optimizations
  data$optim[data$optim == data$exe] <- "all optimizations"
  data$optim <- sapply(data$optim, function(x) {
    x <- gsub("^no-", "", x)  # Remove leading "no-"
    split_values <- unlist(strsplit(as.character(x), "-"))  # Split values by "-"
    paste(split_values, collapse = " ")  # Combine the split values back into a single string
  })
  data$optim[data$optim == "inlining control structs"] <- "inlined control struc."
  data$optim[data$optim == "lower prims"] <- "lowered basic ops"
  data$optim[data$optim == "quickening"] <- "quickening (*)"
  data$optim[data$optim == "superinstructions"] <- "superinstructions (*)"
  data$optim[data$optim == "supernodes"] <- "supernodes (*)"
  
  # renaming exes
  data$exe[data$exe == "TruffleSOM-ast-HotspotCE-jit"] <- "TruffleSOM-graal"
  data$exe[data$exe == "TruffleSOM-bc-HotspotCE-jit"] <- "TruffleSOM-graal-bc"
  data$exe[data$exe == "TruffleSOM-ast-NativeCE-int"] <- "TruffleSOM-native-interp-ast"
  data$exe[data$exe == "TruffleSOM-bc-NativeCE-int"] <- "TruffleSOM-native-interp-bc"
  data$exe[data$exe == "PySOM-ast-int"] <- "RPySOM-ast-interp"
  data$exe[data$exe == "PySOM-bc-int"] <- "RPySOM-bc-interp"
  data$exe[data$exe == "PySOM-ast-jit"] <- "RPySOM-ast-jit"
  data$exe[data$exe == "PySOM-bc-jit"] <- "RPySOM-bc-jit"
  data
}

all_optims <- load_rebench_data_file("../../../benchmark.data")
all_optims <- get_and_format_new_data(all_optims)
unique_optims <- unique(all_optims$optim)

MIN_JIT_ITERATION <- ifelse(max(all_optims$iteration) > 1000, 1000, 0)

color_set_opti <- c('#081d58', '#AADC32FF','#472D7BFF','#3B528BFF','#FDE725FF','#440154FF','#1d91c0','#238b45','#ec7014')
color_set_optims <- set_color_bindings_for_plots(unique_optims, color_set_opti)
```

#### Sec. 5.6.1 Impact on Interpreter Performance

##### Fig. 7 (a) TSOM AST Interpreter

```{r optim-tsom-ast-int, fig.width=8, fig.height=2.2, echo=FALSE}
box_plot_data <- get_data_for_box_plot_optim(all_optims, "TruffleSOM-native-interp-ast")

plot <- box_plot_optim(box_plot_data)
plot
```

##### Fig. 7 (b) TSOM BC Interpreter

```{r optim-tsom-bc-interp, fig.width=8, fig.height=2.2, echo=FALSE}
box_plot_data <- get_data_for_box_plot_optim(all_optims, "TruffleSOM-native-interp-bc")

plot <- box_plot_optim(box_plot_data)
plot
```

##### Fig. 7 (c) PySOM AST Interpreter

```{r optim-pysom-ast-int, fig.width=8, fig.height=2.2, echo=FALSE}
box_plot_data <- get_data_for_box_plot_optim(all_optims, "RPySOM-ast-interp")

plot <- box_plot_optim(box_plot_data)
plot
```

##### Fig. 7 (d) PySOM BC Interpreter

```{r optim-pysom-bc-interp, fig.width=8, fig.height=2.2, echo=FALSE}
box_plot_data <- get_data_for_box_plot_optim(all_optims, "RPySOM-bc-interp")

plot <- box_plot_optim(box_plot_data)
plot
```

#### Sec. 5.6.2 Impact on Peak Performance

##### Fig. 8 (a) TSOM AST with JIT Compilation

```{r optim-tsom-ast-jit, fig.width=8, fig.height=2.2, echo=FALSE}
box_plot_data <- get_data_for_box_plot_optim(all_optims, "TruffleSOM-graal")

plot <- box_plot_optim(box_plot_data)
plot
```

##### Fig. 8 (b) TSOM BC with JIT Compilation

```{r optim-tsom-bc-jit, fig.width=8, fig.height=2.2, echo=FALSE}
box_plot_data <- get_data_for_box_plot_optim(all_optims, "TruffleSOM-graal-bc")

plot <- box_plot_optim(box_plot_data)
plot
```

##### Fig. 8 (c) PySOM AST with JIT Compilation

```{r optim-pysom-ast-jit, fig.width=8, fig.height=2.2, echo=FALSE}
box_plot_data <- get_data_for_box_plot_optim(all_optims, "RPySOM-ast-jit")

plot <- box_plot_optim(box_plot_data)
plot
```

##### Fig. 8 (d) PySOM BC with JIT Compilation

```{r optim-pysom-bc-jit, fig.width=8, fig.height=2.2, echo=FALSE}
box_plot_data <- get_data_for_box_plot_optim(all_optims, "RPySOM-bc-jit")

plot <- box_plot_optim(box_plot_data)
plot
```
